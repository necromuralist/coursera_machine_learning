{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "# Linear Regression With SFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "This is a summary (by example) of how to perform a linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "# third party\n",
    "import graphlab\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns:\n\tHousePrice\tint\n\tHsPrc ($10,000)\tfloat\n\tCrimeRate\tfloat\n\tMilesPhila\tfloat\n\tPopChg\tfloat\n\tName\tstr\n\tCounty\tstr\n\nRows: 10\n\nData:\n+------------+-----------------+-----------+------------+--------+------------+\n| HousePrice | HsPrc ($10,000) | CrimeRate | MilesPhila | PopChg |    Name    |\n+------------+-----------------+-----------+------------+--------+------------+\n|   140463   |     14.0463     |    29.7   |    10.0    |  -1.0  |  Abington  |\n|   113033   |     11.3033     |    24.1   |    18.0    |  4.0   |   Ambler   |\n|   124186   |     12.4186     |    19.5   |    25.0    |  8.0   |   Aston    |\n|   110490   |      11.049     |    49.4   |    25.0    |  2.7   |  Bensalem  |\n|   79124    |      7.9124     |    54.1   |    19.0    |  3.9   | Bristol B. |\n|   92634    |      9.2634     |    48.6   |    20.0    |  0.6   | Bristol T. |\n|   89246    |      8.9246     |    30.8   |    15.0    |  -2.6  | Brookhaven |\n|   195145   |     19.5145     |    10.8   |    20.0    |  -3.5  | Bryn Athyn |\n|   297342   |     29.7342     |    20.2   |    14.0    |  0.6   | Bryn Mawr  |\n|   264298   |     26.4298     |    20.4   |    26.0    |  6.0   | Buckingham |\n+------------+-----------------+-----------+------------+--------+------------+\n+----------+\n|  County  |\n+----------+\n| Montgome |\n| Montgome |\n| Delaware |\n|  Bucks   |\n|  Bucks   |\n|  Bucks   |\n| Delaware |\n| Montgome |\n| Montgome |\n|  Bucks   |\n+----------+\n[10 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parsing completed. Parsed 99 lines in 0.039094 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Finished parsing file /home/cronos/projects/machine_learning/machine_learning/large_data/csvs/Philadelphia_Crime_Rate_noNA.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[int,float,float,float,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parsing completed. Parsed 99 lines in 0.031703 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Finished parsing file /home/cronos/projects/machine_learning/machine_learning/large_data/csvs/Philadelphia_Crime_Rate_noNA.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sales = graphlab.SFrame.read_csv(os.path.join('../../../large_data/csvs/Philadelphia_Crime_Rate_noNA.csv'))\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "## Fit the regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "The target here it the sale-price of a house ('HousePrice') and the prediction variable is the crime-rate in the house's area ('CrimeRate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Create a :class:`~graphlab.linear_regression.LinearRegression` to\n",
      "    predict a scalar target variable as a linear function of one or more\n",
      "    features. In addition to standard numeric and categorical types, features\n",
      "    can also be extracted automatically from list- or dictionary-type SFrame\n",
      "    columns.\n",
      "\n",
      "    The linear regression module can be used for ridge regression, Lasso, and\n",
      "    elastic net regression (see References for more detail on these methods). By\n",
      "    default, this model has an l2 regularization weight of 0.01.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    dataset : SFrame\n",
      "        The dataset to use for training the model.\n",
      "\n",
      "    target : string\n",
      "        Name of the column containing the target variable.\n",
      "\n",
      "    features : list[string], optional\n",
      "        Names of the columns containing features. 'None' (the default) indicates\n",
      "        that all columns except the target variable should be used as features.\n",
      "\n",
      "        The features are columns in the input SFrame that can be of the\n",
      "        following types:\n",
      "\n",
      "        - *Numeric*: values of numeric type integer or float.\n",
      "\n",
      "        - *Categorical*: values of type string.\n",
      "\n",
      "        - *Array*: list of numeric (integer or float) values. Each list element\n",
      "          is treated as a separate feature in the model.\n",
      "\n",
      "        - *Dictionary*: key-value pairs with numeric (integer or float) values\n",
      "          Each key of a dictionary is treated as a separate feature and the\n",
      "          value in the dictionary corresponds to the value of the feature.\n",
      "          Dictionaries are ideal for representing sparse data.\n",
      "\n",
      "        Columns of type *list* are not supported. Convert such feature\n",
      "        columns to type array if all entries in the list are of numeric\n",
      "        types. If the lists contain data of mixed types, separate\n",
      "        them out into different columns.\n",
      "\n",
      "    l2_penalty : float, optional\n",
      "        Weight on the l2-regularizer of the model. The larger this weight, the\n",
      "        more the model coefficients shrink toward 0. This introduces bias into\n",
      "        the model but decreases variance, potentially leading to better\n",
      "        predictions. The default value is 0.01; setting this parameter to 0\n",
      "        corresponds to unregularized linear regression. See the ridge\n",
      "        regression reference for more detail.\n",
      "\n",
      "    l1_penalty : float, optional\n",
      "        Weight on l1 regularization of the model. Like the l2 penalty, the\n",
      "        higher the l1 penalty, the more the estimated coefficients shrink toward\n",
      "        0. The l1 penalty, however, completely zeros out sufficiently small\n",
      "        coefficients, automatically indicating features that are not useful for\n",
      "        the model. The default weight of 0 prevents any features from being\n",
      "        discarded. See the LASSO regression reference for more detail.\n",
      "\n",
      "    solver : string, optional\n",
      "        Solver to use for training the model. See the references for more detail\n",
      "        on each solver.\n",
      "\n",
      "        - *auto (default)*: automatically chooses the best solver for the data\n",
      "          and model parameters.\n",
      "        - *newton*: Newton-Raphson\n",
      "        - *lbfgs*: limited memory BFGS\n",
      "        - *gd*: gradient descent\n",
      "        - *fista*: accelerated gradient descent\n",
      "\n",
      "        The model is trained using a carefully engineered collection of methods\n",
      "        that are automatically picked based on the input data. The ``newton``\n",
      "        method  works best for datasets with plenty of examples and few features\n",
      "        (long datasets). Limited memory BFGS (``lbfgs``) is a robust solver for\n",
      "        wide datasets (i.e datasets with many coefficients).  ``fista`` is the\n",
      "        default solver for l1-regularized linear regression. Gradient-descent\n",
      "        (GD) is another well tuned method that can work really well on\n",
      "        l1-regularized problems.  The solvers are all automatically tuned and\n",
      "        the default options should function well. See the solver options guide\n",
      "        for setting additional parameters for each of the solvers.\n",
      "\n",
      "        See the user guide for additional details on how the solver is chosen.\n",
      "\n",
      "    feature_rescaling : boolean, optional\n",
      "        Feature rescaling is an important pre-processing step that ensures that\n",
      "        all features are on the same scale. An l2-norm rescaling is performed\n",
      "        to make sure that all features are of the same norm. Categorical\n",
      "        features are also rescaled by rescaling the dummy variables that are\n",
      "        used to represent them. The coefficients are returned in original scale\n",
      "        of the problem. This process is particularly useful when features\n",
      "        vary widely in their ranges.\n",
      "\n",
      "    validation_set : SFrame, optional\n",
      "\n",
      "        A dataset for monitoring the model's generalization performance.\n",
      "        For each row of the progress table, the chosen metrics are computed\n",
      "        for both the provided training dataset and the validation_set. The\n",
      "        format of this SFrame must be the same as the training set.\n",
      "        By default this argument is set to 'auto' and a validation set is\n",
      "        automatically sampled and used for progress printing. If\n",
      "        validation_set is set to None, then no additional metrics\n",
      "        are computed. The default value is 'auto'.\n",
      "\n",
      "    convergence_threshold : float, optional\n",
      "\n",
      "      Convergence is tested using variation in the training objective. The\n",
      "      variation in the training objective is calculated using the difference\n",
      "      between the objective values between two steps. Consider reducing this\n",
      "      below the default value (0.01) for a more accurately trained model.\n",
      "      Beware of overfitting (i.e a model that works well only on the training\n",
      "      data) if this parameter is set to a very low value.\n",
      "\n",
      "    lbfgs_memory_level : int, optional\n",
      "\n",
      "      The L-BFGS algorithm keeps track of gradient information from the\n",
      "      previous ``lbfgs_memory_level`` iterations. The storage requirement for\n",
      "      each of these gradients is the ``num_coefficients`` in the problem.\n",
      "      Increasing the ``lbfgs_memory_level`` can help improve the quality of\n",
      "      the model trained. Setting this to more than ``max_iterations`` has the\n",
      "      same effect as setting it to ``max_iterations``.\n",
      "\n",
      "    max_iterations : int, optional\n",
      "\n",
      "      The maximum number of allowed passes through the data. More passes over\n",
      "      the data can result in a more accurately trained model. Consider\n",
      "      increasing this (the default value is 10) if the training accuracy is\n",
      "      low and the *Grad-Norm* in the display is large.\n",
      "\n",
      "    step_size : float, optional (fista only)\n",
      "\n",
      "      The starting step size to use for the ``fista`` and ``gd`` solvers. The\n",
      "      default is set to 1.0, this is an aggressive setting. If the first\n",
      "      iteration takes a considerable amount of time, reducing this parameter\n",
      "      may speed up model training.\n",
      "\n",
      "    verbose : bool, optional\n",
      "        If True, print progress updates.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : LinearRegression\n",
      "        A trained model of type\n",
      "        :class:`~graphlab.linear_regression.LinearRegression`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    LinearRegression, graphlab.boosted_trees_regression.BoostedTreesRegression, graphlab.regression.create\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    - Categorical variables are encoded by creating dummy variables. For a\n",
      "      variable with :math:`K` categories, the encoding creates :math:`K-1` dummy\n",
      "      variables, while the first category encountered in the data is used as the\n",
      "      baseline.\n",
      "\n",
      "    - For prediction and evaluation of linear regression models with sparse\n",
      "      dictionary inputs, new keys/columns that were not seen during training\n",
      "      are silently ignored.\n",
      "\n",
      "    - Any 'None' values in the data will result in an error being thrown.\n",
      "\n",
      "    - A constant term is automatically added for the model intercept. This term\n",
      "      is not regularized.\n",
      "\n",
      "    - Standard errors on coefficients are only availiable when `solver=newton`\n",
      "      or when the default `auto` solver option choses the newton method and if\n",
      "      the number of examples in the training data is more than the number of\n",
      "      coefficients. If standard errors cannot be estimated, a column of `None`\n",
      "      values are returned.\n",
      "\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    - Hoerl, A.E. and Kennard, R.W. (1970) `Ridge regression: Biased Estimation\n",
      "      for Nonorthogonal Problems\n",
      "      <http://amstat.tandfonline.com/doi/abs/10.1080/00401706.1970.10488634>`_.\n",
      "      Technometrics 12(1) pp.55-67\n",
      "\n",
      "    - Tibshirani, R. (1996) `Regression Shrinkage and Selection via the Lasso <h\n",
      "      ttp://www.jstor.org/discover/10.2307/2346178?uid=3739256&uid=2&uid=4&sid=2\n",
      "      1104169934983>`_. Journal of the Royal Statistical Society. Series B\n",
      "      (Methodological) 58(1) pp.267-288.\n",
      "\n",
      "    - Zhu, C., et al. (1997) `Algorithm 778: L-BFGS-B: Fortran subroutines for\n",
      "      large-scale bound-constrained optimization\n",
      "      <http://dl.acm.org/citation.cfm?id=279236>`_. ACM Transactions on\n",
      "      Mathematical Software 23(4) pp.550-560.\n",
      "\n",
      "    - Barzilai, J. and Borwein, J. `Two-Point Step Size Gradient Methods\n",
      "      <http://imajna.oxfordjournals.org/content/8/1/141.short>`_. IMA Journal of\n",
      "      Numerical Analysis 8(1) pp.141-148.\n",
      "\n",
      "    - Beck, A. and Teboulle, M. (2009) `A Fast Iterative Shrinkage-Thresholding\n",
      "      Algorithm for Linear Inverse Problems\n",
      "      <http://epubs.siam.org/doi/abs/10.1137/080716542>`_. SIAM Journal on\n",
      "      Imaging Sciences 2(1) pp.183-202.\n",
      "\n",
      "    - Zhang, T. (2004) `Solving large scale linear prediction problems using\n",
      "      stochastic gradient descent algorithms\n",
      "      <http://dl.acm.org/citation.cfm?id=1015332>`_. ICML '04: Proceedings of\n",
      "      the twenty-first international conference on Machine learning p.116.\n",
      "\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "\n",
      "    Given an :class:`~graphlab.SFrame` ``sf`` with a list of columns\n",
      "    [``feature_1`` ... ``feature_K``] denoting features and a target column\n",
      "    ``target``, we can create a\n",
      "    :class:`~graphlab.linear_regression.LinearRegression` as follows:\n",
      "\n",
      "    >>> data =  graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/regression/houses.csv')\n",
      "\n",
      "    >>> model = graphlab.linear_regression.create(data, target='price',\n",
      "    ...                                  features=['bath', 'bedroom', 'size'])\n",
      "\n",
      "\n",
      "    For ridge regression, we can set the ``l2_penalty`` parameter higher (the\n",
      "    default is 0.01). For Lasso regression, we set the l1_penalty higher, and\n",
      "    for elastic net, we set both to be higher.\n",
      "\n",
      "    .. sourcecode:: python\n",
      "\n",
      "      # Ridge regression\n",
      "      >>> model_ridge = graphlab.linear_regression.create(data, 'price', l2_penalty=0.1)\n",
      "\n",
      "      # Lasso\n",
      "      >>> model_lasso = graphlab.linear_regression.create(data, 'price', l2_penalty=0.,\n",
      "                                                                   l1_penalty=1.0)\n",
      "\n",
      "      # Elastic net regression\n",
      "      >>> model_enet  = graphlab.linear_regression.create(data, 'price', l2_penalty=0.5,\n",
      "                                                                 l1_penalty=0.5)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(graphlab.linear_regression.create.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "crime_model = graphlab.linear_regression.create(sales, target='HousePrice',\n",
    "                                                features=['CrimeRate'],\n",
    "                                                validation_set=None,\n",
    "                                                verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "## Plot the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_data(data, model, title):\n",
    "    figure = plt.figure()\n",
    "    axe = figure.gca()\n",
    "    lines = axe.plot(data['CrimeRate'],data['HousePrice'],'.', label='Data')\n",
    "    lines = axe.plot(data['CrimeRate'], model.predict(data),'-', label='Fit')\n",
    "    label = axe.set_xlabel(\"Crime Rate\")\n",
    "    label = axe.set_ylabel(\"House Price\")\n",
    "    title = axe.set_title(title)\n",
    "    legend = axe.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd921fbbe50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data(sales, crime_model, 'Philadelpdhia Crime Rate vs House Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "## Identify the outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Phila,CC', 'PopChg': 4.8, 'County': 'Phila', 'HousePrice': 96200, 'MilesPhila': 0.0, 'HsPrc ($10,000)': 9.62, 'CrimeRate': 366.1}\n"
     ]
    }
   ],
   "source": [
    "maximum_crime = sales['CrimeRate'].argmax()\n",
    "outlier = sales[maximum_crime]\n",
    "print(outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "## Get the model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+----------------+---------------+\n",
      "|     name    | index |     value      |     stderr    |\n",
      "+-------------+-------+----------------+---------------+\n",
      "| (intercept) |  None | 176626.046881  | 11245.5882194 |\n",
      "|  CrimeRate  |  None | -576.804949058 |  226.90225951 |\n",
      "+-------------+-------+----------------+---------------+\n",
      "[2 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coefficients = crime_model.get('coefficients')\n",
    "\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = -576.80 x + 176626.05\n"
     ]
    }
   ],
   "source": [
    "intercept, slope = coefficients['value']\n",
    "print(\"y = {m:.2f} x + {b:.2f}\".format(m=slope, b=intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "## Predict House Price based on new crime rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Return target value predictions for ``dataset``, using the trained\n",
      "        linear regression model. This method can be used to get fitted values\n",
      "        for the model by inputting the training dataset.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        dataset : SFrame | pandas.Dataframe\n",
      "            Dataset of new observations. Must include columns with the same\n",
      "            names as the features used for model training, but does not require\n",
      "            a target column. Additional columns are ignored.\n",
      "\n",
      "        missing_value_action : str, optional\n",
      "            Action to perform when missing values are encountered. This can be\n",
      "            one of:\n",
      "\n",
      "            - 'auto': Default to 'impute'\n",
      "            - 'impute': Proceed with evaluation by filling in the missing\n",
      "              values with the mean of the training data. Missing\n",
      "              values are also imputed if an entire column of data is\n",
      "              missing during evaluation.\n",
      "            - 'error': Do not proceed with prediction and terminate with\n",
      "              an error message.\n",
      "\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        out : SArray\n",
      "            Predicted target value for each example (i.e. row) in the dataset.\n",
      "\n",
      "        See Also\n",
      "        ----------\n",
      "        create, evaluate\n",
      "\n",
      "        Examples\n",
      "        ----------\n",
      "        >>> data =  graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/regression/houses.csv')\n",
      "\n",
      "        >>> model = graphlab.linear_regression.create(data,\n",
      "                                             target='price',\n",
      "                                             features=['bath', 'bedroom', 'size'])\n",
      "        >>> results = model.predict(data)\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(crime_model.predict.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Although I'm predicting values, I'll use real data points so that the values can be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 159494.94\n",
      "Actual: 140463.00\n",
      "Difference: 19031.94\n"
     ]
    }
   ],
   "source": [
    "new_data = graphlab.SFrame({'CrimeRate': [sales[0]['CrimeRate']]})\n",
    "prediction = crime_model.predict(new_data)\n",
    "actual = sales[0]['HousePrice']\n",
    "print(\"Prediction: {0:.2f}\".format(prediction[0]))\n",
    "print(\"Actual: {0:.2f}\".format(actual))\n",
    "print('Difference: {0:.2f}'.format(prediction[0] - actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: -34542.24\n",
      "Actual Data: 96200.00\n",
      "Error predicting the outlier: 130742.24\n"
     ]
    }
   ],
   "source": [
    "outlier_check = crime_model.predict(outlier)\n",
    "print(\"Prediction: {0:.2f}\".format(outlier_check[0]))\n",
    "print(\"Actual Data: {0:.2f}\".format(outlier['HousePrice']))\n",
    "print(\"Error predicting the outlier: {0:.2f}\".format(outlier['HousePrice'] - outlier_check[0]))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
